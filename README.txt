1. code\
	1.1. pre-processing\
		The pre-processing code is written in Java. The pre-processing order is 1) delete invalid processes, 2) transfroming to Petri nets, 3) extracting relations.

		1.1.1. lib\
			It contains .jar file used for read and write json.

		1.1.2. src\DeleteInvalidProcesses.java
			This file is used to ensure that all models are lowercased and only letters are remained, and non-English models and the ones without activity names are deleted from the dataset. It also rewrite the .json files from BPMAI.

			line 26 root: root directory
			line 28 coverOldFile: replace old file or not

		1.1.3. src\transforming to petri nets
			The files in this directory are used to transform BPMN processes to Petri nets. The two files are for slient and visible strategy respectively.

			TransformToPetriNet_*.java:
				line 26 root: root directory
				line 28 coverOldFile: replace old file or not

		1.1.4. src\extracting relations
			The files in this directory are used to extract relations.

			1.1.4.1. LRD\
				The files here are used to extract relations from LRD, i.e. the generated Petri nets. Three kinds of relations are extracted by different files.

				ExtractRelationship_*.java:
					line 25 root: root directory
					line 27 coverOldFile: replace old file or not
					line 28 outputRoot: output directory

			1.1.4.2. SRD&SSD\
				The files here are used to extract relations from SRD or SSD, i.e. the matrix used in [1]. Three kinds of relations are extracted by different files.

				FromMatrixToRelationship_*.java:
					line 15 rootPath: root directory
					line 16 workflowFileName: input file
					line 17 outputRoot: output directory

	1.2. training&recommending\
		The training and evaluating code is written in Python3. The code is based on TransE [2], forked from https://github.com/ZichaoHuang/TransE.

		TransRecommendationF1_*_*\src\main.py:
			FIle main.py is the access of training and testing. It also contains experiment settings.

			line 12 data_dir: dataset directory
			line 13 embedding_dim: dimension k
			line 14 margin_value: margin value Î³
			line 15 score_func: distance function d (L1: Manhattan distance, L2: Euclidean metric)
			line 16 batch_size: training batch size
			line 17 eval_batch_size: evaluating batch size
			line 18 learning_rate: learning rate
			line 23 max_epoch: total training rounds
			line 24 eval_freq: training rounds per evaluate
			line 25 log_file: result directory

		TransRecommendationF1_*_*\src\dataset.py:
			FIle dataset.py is the used to read trainging, testing and validation relation sets.

		TransRecommendationF1_*_*\src\model.py:
			FIle model.py is the used to train representation learning model and evaluate the trained model (i.e. evaluate our recommendation method).

2. dataset\
	2.1. LRD\
		You can get LRD from http://bpmai.org/. This is a large real-life dataset. It is only free for academic propose.

	2.2. SRD\
		This is the small real-life dataset first used in [1]. It is collected from a district government in Hangzhou city, China.

		2.2.1. raw workflow\
			In this folder, each doc or xls file contains the flowchart and description of raw workflows.

		2.2.2. final workflow\
			workflow.txt
				[1] has already converted raw workflows to matrix format. Each matrix represents a workflow converted from raw workflow manually. The elements in the matrix's diagonal denote activity nodes in raw workflows, while the other elements represent edges in raw workflows.

				For Example, the workflow "a to b to d to c" can be represented as matrix:
				[a 1 0 0]
				[0 b 0 1]
				[0 0 c 0]
				[0 0 1 d]

	2.3. SSD\
		These are the small synthetic datasets generated and used in [1]. They are generated by the method similar with the one proposed by [3].

		2.3.1. rules.txt
			This is a transitional probability matrix M which decides the order of nodes appearing in synthetic workflows.

		2.3.2. synthetic workflow\
			Each file contains synthetic workflows in matrix format. The elements in the matrix's diagonal denote activity nodes in workflow, while the other elements represent edges in workflows.

3. result\
	Result files are the output of training and recommending files. You can see the training and recommendation process.

	In a result file, RAW means recommendation is done through all activities, FILTER means recommendation is done through all activities except the other correct ones. For example, we have process "a to {b, c, d}", and for activity "b", we will delete "c" and "d" from the candidates in FILTER. (For activity "c", we will delete "b" and "d" from the candidates in FILTER & for activity "d", we will delete "b" and "c" from the candidates in FILTER, respectively.)

	HEAD PREDICTION means we predict head with tail and TAIL PREDICTION vice versa. AVERAGE is the average of head and tail prediction. HITS, PRECISION, RECALL and F1 are the four metrics in our paper, and @N means we recommend N activities.

	Thus, hits in FILTER TAIL PREDICTION is our actual HitRate!!! Precision, recall and f1 in RAW TAIL PREDICTION is our actual precision, recall and F1 score!!!

	3.1. LRD\
		The results of LRD.

	3.2. SRD\
		The results of SRD. We generate "small_real.xlsx" to gather statistics. Four sheets are for four benchmarks.

	3.3. SSD\
		The results of SSD. We generate "small_synthetic.xlsx" to gather statistics. Four sheets are for four benchmarks.


[1] Deng, S., Wang, D., Li, Y., Cao, B., Yin, J., & Wu, Z., et al. A recommendation system to facilitate business process modeling. IEEE Transactions on Cybernetics, 47(6), 1380-1394. (2017).

[2] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., & Yakhnenko, O. Translating embeddings for modeling multi-relational data. Advances in Neural Information Processing Systems, 2787-2795. (2013).

[3] Zhang, J., Liu, Q., & Xu, K. FlowRecommender: a workflow recommendation technique for process provenance. Eighth Australasian Data Mining Conference. (2009).

P.S. Other unused results may be used in some situation. For example, head prediction can be used to check the validation of each node in constructed models.